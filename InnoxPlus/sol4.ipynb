{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\ADMIN\\Desktop\\innox\\train_F3WbcTw.csv')\n",
    "df1=pd.read_csv(r'C:\\Users\\ADMIN\\Desktop\\innox\\test_tOlRoBf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ([x for x in x.split() if x.lower() not in stop]))\n",
    "df1['text'] = df1['text'].apply(lambda x: ([x for x in x.split() if x.lower() not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ([y for y in x if  len(y)>2 ]))\n",
    "df1['text'] = df1['text'].apply(lambda x: ([y for y in x if len(y)>2 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_w=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(lambda x: ' '.join([each for each in x if each not in sp_w]))\n",
    "df1['text']=df1['text'].apply(lambda x: ' '.join([each for each in x if each not in sp_w]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "df1['text'] = df1['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Autoimmune diseases tend come clusters Gilenya...\n",
       "1       completely understand youd want try it But res...\n",
       "2       Interesting targets SP receptors rather  like ...\n",
       "3       interesting grand merci wonder lemtrada ocrevu...\n",
       "4       everybody latest MRI results Brain Cervical Co...\n",
       "5       cant give advice Lemtrada chose Cladribine tho...\n",
       "6       Reply posted JessZidek Jess Sorry read challen...\n",
       "7       Well expected Neurologist wants start Tysabri ...\n",
       "8       think FIngolimod miserable failure progressive...\n",
       "9       Thank muchIm learning lot GRACE mentioned husb...\n",
       "10      vision one eye unrelated eye injections Howeve...\n",
       "11      significant bleeding right eye need laser poss...\n",
       "12      Objective review evidence supporting European ...\n",
       "13      Multiple sclerosis MS thought inflammatory pro...\n",
       "14      Moms diagnosis similar own Mine detected Janua...\n",
       "15      Humira adalimumab injectable protein antibody ...\n",
       "16      Well theory telling accurate standard practice...\n",
       "17      goodness Minnie really wish could use curse wo...\n",
       "18      Sebastian agreed entirely know Alemtuzumab due...\n",
       "19      Good luck Reg days ago went listen top neuro s...\n",
       "20      BMC Ophthalmol  Jan  Intravitreal dexamethason...\n",
       "21      father EGFR exon insertion mutation found toda...\n",
       "22      Reply posted flower girl Hi years got pregnant...\n",
       "23      Hello Snigdha father diagnosed lung cancer Jul...\n",
       "24      first recommended Stanford oncologist last rec...\n",
       "25      mention recent developments issues interest re...\n",
       "26      course shortly posted everything good update b...\n",
       "27      Rituxan this main drug Rituxan technically app...\n",
       "28      Last Updated January   Share Comments  TellaFr...\n",
       "29      rebif year rotate injection sites remember tak...\n",
       "                              ...                        \n",
       "5249    Todays post last threepart series Burt stem ce...\n",
       "5250    Thanks everyone made feel alot better Im defin...\n",
       "5251    Dar nice news youand good news third Ocrevus i...\n",
       "5252    Dear BMJ Glad hear loved ones well Tarceva BMJ...\n",
       "5253    hes talking DMTs relapsing remitting MS good c...\n",
       "5254    Tecfidera may available except Scotland unless...\n",
       "5255    Urgh chilli con carne dinner followed massive ...\n",
       "5256    Im Janet FreemanDaily cofounder ROSders Im wri...\n",
       "5257    end wheelchair lot people catastrophic reactio...\n",
       "5258    Thanks responses edgarleroy found cladribine s...\n",
       "5259    Introduction need effective safe treatment pre...\n",
       "5260    Docetaxel week weeks week claim less harsh eff...\n",
       "5261    Swollen lymph nodes good reason doctor look it...\n",
       "5262    couple people said Remistart it new name still...\n",
       "5263    Osimertinib cancer medicine interferes growth ...\n",
       "5264    doesnt Vitrectomy permanently affect vision Li...\n",
       "5265    Oral fingolimod primary progressive multiple s...\n",
       "5266    Hello wife treated lung cancer Tarceva blood w...\n",
       "5267    Robert pray get good results CT wanted Durvalu...\n",
       "5268    Cea numbers  Fingers crossed Also reading post...\n",
       "5269    started Gilenya screening asked heart issues a...\n",
       "5270    flares get worse time same first flare indeed ...\n",
       "5271    Choroidal neovascularization characteristic we...\n",
       "5272    Jan    JimP wrote think depends lot factors st...\n",
       "5273    del also carry comparative simulations EGFR co...\n",
       "5274    Bee Thanks update good news scan Its hard say ...\n",
       "5275    blood testing done check levels Humira trough ...\n",
       "5276                                  best husband family\n",
       "5277    bazza luckily eyes badly affected get headache...\n",
       "5278    Well appeared mild number years relapses takin...\n",
       "Name: text, Length: 5279, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text']=df1['text'].apply(lambda x: [i for i in x.split() if not str(i).isdigit()])\n",
    "df['text']=df['text'].apply(lambda x: [i for i in x.split() if not str(i).isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [previously, stable, natalizumab, switching, f...\n",
       "1       [fingolimod, since, December, way, describe, b...\n",
       "2       [Apparently, shingles, red, spots, left, breas...\n",
       "3       [Docetaxel, week, weeks, week, claim, less, ha...\n",
       "4       [CC, Stelara, worked, matter, days, me, willin...\n",
       "5       [Janssen, Biotech, Inc, received, FDA, approva...\n",
       "6       [the, thought, things, would, better, now, one...\n",
       "7       [Dec, Basha, Fowler, diagnosed, rd, week, Dec,...\n",
       "8       [Hi, started, Gilenya, weeks, ago, woeful, anx...\n",
       "9       [uncle, still, going, treatment, kinds, Chemo,...\n",
       "10      [daughter, Stage, adenocarcinoma, NSCLC, ROS, ...\n",
       "11      [nt, Toxicity, would, probably, main, objectio...\n",
       "12      [Thanks, Jim, Thanks, Janine, Kidney, failure,...\n",
       "13      [Hey, iPoop, tried, clicking, link, work, went...\n",
       "14      [Bad, lifetime, nearsightedness, os, led, macu...\n",
       "15      [Janine, ever, heard, KRAS, mutation, mutating...\n",
       "16      [The, important, metric, brain, volume, loss, ...\n",
       "17      [Hello, guys, hope, well, know, post, topic, e...\n",
       "18      [all, first, scan, taking, Tagrisso, weeks, sc...\n",
       "19      [NICE, turns, daclizumab, MSers, NHS, NewsSpea...\n",
       "20      [overthinking, this, ask, see, accepts, first,...\n",
       "21      [Thanks, Clo, dunno, much, longer, like, for, ...\n",
       "22      [Neurology, Jul, ee, abstract, Read, full, tex...\n",
       "23      [thought, another, reason, people, picking, HS...\n",
       "24      [Replies, Plan, official, Ocrevus, Views, Post...\n",
       "25      [Researchers, evaluated, macular, pigment, dis...\n",
       "26      [beachgirl, gain, weight, Gilenya, Remained, c...\n",
       "27      [Hi, Ive, gilenya, nearly, three, years, now, ...\n",
       "28      [Comprehensive, discussion, side, effects, acr...\n",
       "29      [drug, causes, apoptosis, slow, kill, rather, ...\n",
       "                              ...                        \n",
       "2894    [mlgilber, long, take, started, noticing, diff...\n",
       "2895    [watsoncraig, would, suggest, researching, Rit...\n",
       "2896    [all, wanted, bring, post, back, discussion, a...\n",
       "2897    [lamn, hope, mom, well, tagrisso, long, time, ...\n",
       "2898    [Hi, currently, receiving, adjuvant, chemother...\n",
       "2899    [mechanisms, different, targets, different, Ke...\n",
       "2900    [Ang, Plegridy, kind, beta, interferon, Avonex...\n",
       "2901    [Multicenter, observational, French, study, co...\n",
       "2902    [Mom, PETCT, yesterday, showed, mets, liver, l...\n",
       "2903    [Natalie, asks, Barry, people, looking, ECTRIM...\n",
       "2904    [mother, diagnosed, stage, locally, advancedlu...\n",
       "2905    [Im, back, hospital, looking, likely, fail, Re...\n",
       "2906    [year, substantial, progress, multiple, sclero...\n",
       "2907    [Mom, first, round, keytruda, yesterday, said,...\n",
       "2908    [US, Inflectra, Ixifi, Remicade, Renflexis, Av...\n",
       "2909    [US, Food, Drug, Administration, FDA, approves...\n",
       "2910    [Home, Information, Publications, Research, Up...\n",
       "2911    [Oral, BG, fumaric, acid, ester, studied, pati...\n",
       "2912    [subgroups, progressive, treated, Dr, Xavier, ...\n",
       "2913    [all, Looking, big, advice, Ive, since, really...\n",
       "2914    [Hello, Creelan, thank, reply, Since, dont, pr...\n",
       "2915    [mother, participated, trial, Pebroluzimab, Ju...\n",
       "2916    [diagnosed, crohns, disease, two, bowel, resec...\n",
       "2917    [Hi, diagnosed, Monday, Lupus, told, Rheumy, t...\n",
       "2918    [Hi, sick, recently, think, flu, took, care, d...\n",
       "2919    [Reply, posted, Hippopostrous, sorry, read, da...\n",
       "2920    [Lorraine, Thats, crap, shame, stop, Tysabri, ...\n",
       "2921    [jskozio, sounds, like, nonsense, me, Experime...\n",
       "2922    [sounds, like, well, FG, worried, complete, re...\n",
       "2923    [rambles, too, Its, hard, decision, isnt, it, ...\n",
       "Name: text, Length: 2924, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Autoimmune, diseases, tend, come, clusters, G...\n",
       "1       [completely, understand, youd, want, try, it, ...\n",
       "2       [Interesting, targets, SP, receptors, rather, ...\n",
       "3       [interesting, grand, merci, wonder, lemtrada, ...\n",
       "4       [everybody, latest, MRI, results, Brain, Cervi...\n",
       "5       [cant, give, advice, Lemtrada, chose, Cladribi...\n",
       "6       [Reply, posted, JessZidek, Jess, Sorry, read, ...\n",
       "7       [Well, expected, Neurologist, wants, start, Ty...\n",
       "8       [think, FIngolimod, miserable, failure, progre...\n",
       "9       [Thank, muchIm, learning, lot, GRACE, mentione...\n",
       "10      [vision, one, eye, unrelated, eye, injections,...\n",
       "11      [significant, bleeding, right, eye, need, lase...\n",
       "12      [Objective, review, evidence, supporting, Euro...\n",
       "13      [Multiple, sclerosis, MS, thought, inflammator...\n",
       "14      [Moms, diagnosis, similar, own, Mine, detected...\n",
       "15      [Humira, adalimumab, injectable, protein, anti...\n",
       "16      [Well, theory, telling, accurate, standard, pr...\n",
       "17      [goodness, Minnie, really, wish, could, use, c...\n",
       "18      [Sebastian, agreed, entirely, know, Alemtuzuma...\n",
       "19      [Good, luck, Reg, days, ago, went, listen, top...\n",
       "20      [BMC, Ophthalmol, Jan, Intravitreal, dexametha...\n",
       "21      [father, EGFR, exon, insertion, mutation, foun...\n",
       "22      [Reply, posted, flower, girl, Hi, years, got, ...\n",
       "23      [Hello, Snigdha, father, diagnosed, lung, canc...\n",
       "24      [first, recommended, Stanford, oncologist, las...\n",
       "25      [mention, recent, developments, issues, intere...\n",
       "26      [course, shortly, posted, everything, good, up...\n",
       "27      [Rituxan, this, main, drug, Rituxan, technical...\n",
       "28      [Last, Updated, January, Share, Comments, Tell...\n",
       "29      [rebif, year, rotate, injection, sites, rememb...\n",
       "                              ...                        \n",
       "5249    [Todays, post, last, threepart, series, Burt, ...\n",
       "5250    [Thanks, everyone, made, feel, alot, better, I...\n",
       "5251    [Dar, nice, news, youand, good, news, third, O...\n",
       "5252    [Dear, BMJ, Glad, hear, loved, ones, well, Tar...\n",
       "5253    [hes, talking, DMTs, relapsing, remitting, MS,...\n",
       "5254    [Tecfidera, may, available, except, Scotland, ...\n",
       "5255    [Urgh, chilli, con, carne, dinner, followed, m...\n",
       "5256    [Im, Janet, FreemanDaily, cofounder, ROSders, ...\n",
       "5257    [end, wheelchair, lot, people, catastrophic, r...\n",
       "5258    [Thanks, responses, edgarleroy, found, cladrib...\n",
       "5259    [Introduction, need, effective, safe, treatmen...\n",
       "5260    [Docetaxel, week, weeks, week, claim, less, ha...\n",
       "5261    [Swollen, lymph, nodes, good, reason, doctor, ...\n",
       "5262    [couple, people, said, Remistart, it, new, nam...\n",
       "5263    [Osimertinib, cancer, medicine, interferes, gr...\n",
       "5264    [doesnt, Vitrectomy, permanently, affect, visi...\n",
       "5265    [Oral, fingolimod, primary, progressive, multi...\n",
       "5266    [Hello, wife, treated, lung, cancer, Tarceva, ...\n",
       "5267    [Robert, pray, get, good, results, CT, wanted,...\n",
       "5268    [Cea, numbers, Fingers, crossed, Also, reading...\n",
       "5269    [started, Gilenya, screening, asked, heart, is...\n",
       "5270    [flares, get, worse, time, same, first, flare,...\n",
       "5271    [Choroidal, neovascularization, characteristic...\n",
       "5272    [Jan, JimP, wrote, think, depends, lot, factor...\n",
       "5273    [del, also, carry, comparative, simulations, E...\n",
       "5274    [Bee, Thanks, update, good, news, scan, Its, h...\n",
       "5275    [blood, testing, done, check, levels, Humira, ...\n",
       "5276                              [best, husband, family]\n",
       "5277    [bazza, luckily, eyes, badly, affected, get, h...\n",
       "5278    [Well, appeared, mild, number, years, relapses...\n",
       "Name: text, Length: 5279, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {ord(x):\"\" for x in \":-()&*$%@!#|\\{[]}/,' '.:; \"}\n",
    "df['text']=df['text'].apply(lambda orig_list : [x.translate(d) for x in orig_list])\n",
    "df1['text']=df1['text'].apply(lambda orig_list : [x.translate(d) for x in orig_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['texts']=df1['text'].apply(lambda x: [i.lower() for i in x if len(str(i))>2])\n",
    "df['texts']=df['text'].apply(lambda x: [i.lower() for i in x if len(str(i))>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [previously, stable, natalizumab, switching, f...\n",
       "1       [fingolimod, since, december, way, describe, b...\n",
       "2       [apparently, shingles, red, spots, left, breas...\n",
       "3       [docetaxel, week, weeks, week, claim, less, ha...\n",
       "4       [stelara, worked, matter, days, willing, jump,...\n",
       "5       [janssen, biotech, inc, received, fda, approva...\n",
       "6       [the, thought, things, would, better, now, one...\n",
       "7       [dec, basha, fowler, diagnosed, week, dec, egf...\n",
       "8       [started, gilenya, weeks, ago, woeful, anxiety...\n",
       "9       [uncle, still, going, treatment, kinds, chemo,...\n",
       "10      [daughter, stage, adenocarcinoma, nsclc, ros, ...\n",
       "11      [toxicity, would, probably, main, objection, c...\n",
       "12      [thanks, jim, thanks, janine, kidney, failure,...\n",
       "13      [hey, ipoop, tried, clicking, link, work, went...\n",
       "14      [bad, lifetime, nearsightedness, led, macular,...\n",
       "15      [janine, ever, heard, kras, mutation, mutating...\n",
       "16      [the, important, metric, brain, volume, loss, ...\n",
       "17      [hello, guys, hope, well, know, post, topic, e...\n",
       "18      [all, first, scan, taking, tagrisso, weeks, sc...\n",
       "19      [nice, turns, daclizumab, msers, nhs, newsspea...\n",
       "20      [overthinking, this, ask, see, accepts, first,...\n",
       "21      [thanks, clo, dunno, much, longer, like, for, ...\n",
       "22      [neurology, jul, abstract, read, full, text, p...\n",
       "23      [thought, another, reason, people, picking, hs...\n",
       "24      [replies, plan, official, ocrevus, views, post...\n",
       "25      [researchers, evaluated, macular, pigment, dis...\n",
       "26      [beachgirl, gain, weight, gilenya, remained, c...\n",
       "27      [ive, gilenya, nearly, three, years, now, annu...\n",
       "28      [comprehensive, discussion, side, effects, acr...\n",
       "29      [drug, causes, apoptosis, slow, kill, rather, ...\n",
       "                              ...                        \n",
       "2894    [mlgilber, long, take, started, noticing, diff...\n",
       "2895    [watsoncraig, would, suggest, researching, rit...\n",
       "2896    [all, wanted, bring, post, back, discussion, a...\n",
       "2897    [lamn, hope, mom, well, tagrisso, long, time, ...\n",
       "2898    [currently, receiving, adjuvant, chemotherapy,...\n",
       "2899    [mechanisms, different, targets, different, ke...\n",
       "2900    [ang, plegridy, kind, beta, interferon, avonex...\n",
       "2901    [multicenter, observational, french, study, co...\n",
       "2902    [mom, petct, yesterday, showed, mets, liver, l...\n",
       "2903    [natalie, asks, barry, people, looking, ectrim...\n",
       "2904    [mother, diagnosed, stage, locally, advancedlu...\n",
       "2905    [back, hospital, looking, likely, fail, remica...\n",
       "2906    [year, substantial, progress, multiple, sclero...\n",
       "2907    [mom, first, round, keytruda, yesterday, said,...\n",
       "2908    [inflectra, ixifi, remicade, renflexis, availa...\n",
       "2909    [food, drug, administration, fda, approves, os...\n",
       "2910    [home, information, publications, research, up...\n",
       "2911    [oral, fumaric, acid, ester, studied, patients...\n",
       "2912    [subgroups, progressive, treated, xavier, mont...\n",
       "2913    [all, looking, big, advice, ive, since, really...\n",
       "2914    [hello, creelan, thank, reply, since, dont, pr...\n",
       "2915    [mother, participated, trial, pebroluzimab, ju...\n",
       "2916    [diagnosed, crohns, disease, two, bowel, resec...\n",
       "2917    [diagnosed, monday, lupus, told, rheumy, take,...\n",
       "2918    [sick, recently, think, flu, took, care, dad, ...\n",
       "2919    [reply, posted, hippopostrous, sorry, read, da...\n",
       "2920    [lorraine, thats, crap, shame, stop, tysabri, ...\n",
       "2921    [jskozio, sounds, like, nonsense, experimental...\n",
       "2922    [sounds, like, well, worried, complete, remiss...\n",
       "2923    [rambles, too, its, hard, decision, isnt, neur...\n",
       "Name: texts, Length: 2924, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texts'] = df['texts'].apply(lambda x: [Word(word).lemmatize() for word in x])\n",
    "df1['texts'] = df1['texts'].apply(lambda x: [Word(word).lemmatize() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [autoimmune, disease, tend, come, cluster, gil...\n",
       "1       [completely, understand, youd, want, try, but,...\n",
       "2       [interesting, target, receptor, rather, like, ...\n",
       "3       [interesting, grand, merci, wonder, lemtrada, ...\n",
       "4       [everybody, latest, mri, result, brain, cervic...\n",
       "5       [cant, give, advice, lemtrada, chose, cladribi...\n",
       "6       [reply, posted, jesszidek, jess, sorry, read, ...\n",
       "7       [well, expected, neurologist, want, start, tys...\n",
       "8       [think, fingolimod, miserable, failure, progre...\n",
       "9       [thank, muchim, learning, lot, grace, mentione...\n",
       "10      [vision, one, eye, unrelated, eye, injection, ...\n",
       "11      [significant, bleeding, right, eye, need, lase...\n",
       "12      [objective, review, evidence, supporting, euro...\n",
       "13      [multiple, sclerosis, thought, inflammatory, p...\n",
       "14      [mom, diagnosis, similar, own, mine, detected,...\n",
       "15      [humira, adalimumab, injectable, protein, anti...\n",
       "16      [well, theory, telling, accurate, standard, pr...\n",
       "17      [goodness, minnie, really, wish, could, use, c...\n",
       "18      [sebastian, agreed, entirely, know, alemtuzuma...\n",
       "19      [good, luck, reg, day, ago, went, listen, top,...\n",
       "20      [bmc, ophthalmol, jan, intravitreal, dexametha...\n",
       "21      [father, egfr, exon, insertion, mutation, foun...\n",
       "22      [reply, posted, flower, girl, year, got, pregn...\n",
       "23      [hello, snigdha, father, diagnosed, lung, canc...\n",
       "24      [first, recommended, stanford, oncologist, las...\n",
       "25      [mention, recent, development, issue, interest...\n",
       "26      [course, shortly, posted, everything, good, up...\n",
       "27      [rituxan, this, main, drug, rituxan, technical...\n",
       "28      [last, updated, january, share, comment, tella...\n",
       "29      [rebif, year, rotate, injection, site, remembe...\n",
       "                              ...                        \n",
       "5249    [today, post, last, threepart, series, burt, s...\n",
       "5250    [thanks, everyone, made, feel, alot, better, d...\n",
       "5251    [dar, nice, news, youand, good, news, third, o...\n",
       "5252    [dear, bmj, glad, hear, loved, one, well, tarc...\n",
       "5253    [he, talking, dmts, relapsing, remitting, good...\n",
       "5254    [tecfidera, may, available, except, scotland, ...\n",
       "5255    [urgh, chilli, con, carne, dinner, followed, m...\n",
       "5256    [janet, freemandaily, cofounder, rosders, writ...\n",
       "5257    [end, wheelchair, lot, people, catastrophic, r...\n",
       "5258    [thanks, response, edgarleroy, found, cladribi...\n",
       "5259    [introduction, need, effective, safe, treatmen...\n",
       "5260    [docetaxel, week, week, week, claim, le, harsh...\n",
       "5261    [swollen, lymph, node, good, reason, doctor, l...\n",
       "5262    [couple, people, said, remistart, new, name, s...\n",
       "5263    [osimertinib, cancer, medicine, interferes, gr...\n",
       "5264    [doesnt, vitrectomy, permanently, affect, visi...\n",
       "5265    [oral, fingolimod, primary, progressive, multi...\n",
       "5266    [hello, wife, treated, lung, cancer, tarceva, ...\n",
       "5267    [robert, pray, get, good, result, wanted, durv...\n",
       "5268    [cea, number, finger, crossed, also, reading, ...\n",
       "5269    [started, gilenya, screening, asked, heart, is...\n",
       "5270    [flare, get, worse, time, same, first, flare, ...\n",
       "5271    [choroidal, neovascularization, characteristic...\n",
       "5272    [jan, jimp, wrote, think, depends, lot, factor...\n",
       "5273    [del, also, carry, comparative, simulation, eg...\n",
       "5274    [bee, thanks, update, good, news, scan, it, ha...\n",
       "5275    [blood, testing, done, check, level, humira, t...\n",
       "5276                              [best, husband, family]\n",
       "5277    [bazza, luckily, eye, badly, affected, get, he...\n",
       "5278    [well, appeared, mild, number, year, relapse, ...\n",
       "Name: texts, Length: 5279, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "df3=pd.DataFrame()\n",
    "df4=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text']=df1['texts']\n",
    "df3['text']=df['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords=[]\n",
    "for each in df4['text']:\n",
    "    #print(each)\n",
    "    \n",
    "    #eachs =each.split(' ')\n",
    "\n",
    "    allwords.extend(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=Counter(allwords)\n",
    "list_of_word=dictionary.keys()\n",
    "keyss=[]\n",
    "for i in list_of_word:\n",
    "    if i.isalpha()==False or len(i)<4:\n",
    "        keyss.append(i)\n",
    "    #if len(i)==1:\n",
    "        #keyss.append(i)\n",
    "#print(keyss)  \n",
    "for i in keyss:\n",
    "    dictionary.pop(i)\n",
    "dictionary=dictionary.most_common(3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.zeros((2924,3000))\n",
    "#train_labels=np.zeros(5279)\n",
    "docID=0\n",
    "for i in range(df1.shape[0]):\n",
    "    #allwords=[]\n",
    "    words=df1['texts'][i]\n",
    "    #words = line.split(' ')\n",
    "    allwords=[]\n",
    "    allword=Counter(words)\n",
    "    allwords+=allword.keys()\n",
    "    for word in allwords:\n",
    "        wordID = 0\n",
    "        for j,d in enumerate(dictionary):\n",
    "            if d[0] == word:\n",
    "                wordID = j\n",
    "                features_test[docID][wordID] = words.count(word)\n",
    "    #train_labels[docID] = df['sentiment'][i]\n",
    "    docID = docID + 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.zeros((2924,3000))\n",
    "#train_labels=np.zeros(5279)\n",
    "docID=0\n",
    "for i in range(df1.shape[0]):\n",
    "    #allwords=[]\n",
    "    words=df1['texts'][i]\n",
    "    #words = line.split(' ')\n",
    "    allwords=[]\n",
    "    allword=Counter(words)\n",
    "    allwords+=allword.keys()\n",
    "    for word in allwords:\n",
    "        wordID = 0\n",
    "        for j,d in enumerate(dictionary):\n",
    "            if d[0] == word:\n",
    "                wordID = j\n",
    "                features_test[docID][wordID] = words.count(word)\n",
    "    #train_labels[docID] = df['sentiment'][i]\n",
    "    docID = docID + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "method=SMOTE(kind='regular')\n",
    "x_train,y_train=method.fit_sample(features_matrix,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 3).fit(x_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(features_test) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 2., 2., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = svm_model_linear.score(X_test, y_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717323109097247\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y,nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid,cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(svc_param_selection(X_train,y_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=svm.SVC(C=10,kernel='rbf',gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[925   2  47]\n",
      " [  2 888  46]\n",
      " [ 82 105 772]]\n"
     ]
    }
   ],
   "source": [
    "pred=clf.predict(X_test)\n",
    "cm1 = confusion_matrix(y_test, pred)\n",
    "print(cm1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pry=clf.predict(features_test)\n",
    "p1=pd.DataFrame()\n",
    "p1['unique_hash']=df1['unique_hash']\n",
    "p1['sentiment']=pry\n",
    "p1.to_csv(r'C:\\Users\\ADMIN\\Desktop\\innox\\sol4.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(random_state=0,solver='1bfgs',multi_class='multinomial').fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
